{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### КЛАССИФИКАЦИЯ ИЗОБРАЖЕНИЙ НА ОСНОВЕ ТЕКСТА ДОКУМЕНТА И САМОГО ИЗОБРАЖЕНИЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данильченко Вадим"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Документ как может содержать текст, так и нет, соответственно если текста нет, он считается \"unknown\", далее в генераторах подгружаем изображения с диска из заранее подготовленного батча определенного размера (то есть не держим все изображения в памяти, а только нужные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm, os, joblib, math, re, random\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical, Sequence\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from pytesseract import image_to_string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 31/31 [00:00<00:00, 1295.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# создадим список модель-класс\n",
    "path = 'F:\\documents'\n",
    "file2classname = []\n",
    "for subpath in tqdm.tqdm(os.listdir(path)):\n",
    "    if subpath!='result':\n",
    "        for filename in os.listdir(os.path.join(path, subpath)):\n",
    "            if any([_ in filename.lower() for _ in ['.pdf', '.jpeg', '.jpg', '.bmp', '.png']]):\n",
    "                file2classname.append([subpath, filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3351, 3)\n"
     ]
    }
   ],
   "source": [
    "file2class = pd.DataFrame(file2classname)\n",
    "file2class.columns = ['category', 'filename']\n",
    "file2class['target'] = file2class['category'].astype('category').cat.codes\n",
    "print(file2class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем обучающую и проверочную выборки\n",
    "vaidation_split = 0.2\n",
    "batch = 5\n",
    "\n",
    "labels = to_categorical(np.asarray(file2class['target'].tolist()))\n",
    "im_list = file2class[['category', 'filename']].apply(lambda x: os.path.join(path, x[0], x[1]), axis=1).tolist()\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(im_list, \n",
    "                                                    labels, \n",
    "                                                    test_size=vaidation_split, \n",
    "                                                    random_state=777,\n",
    "                                                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[23671,\n",
       "  86,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  8,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  2,\n",
       "  23671,\n",
       "  39,\n",
       "  23671,\n",
       "  23671,\n",
       "  8,\n",
       "  23671,\n",
       "  57,\n",
       "  105,\n",
       "  67,\n",
       "  23671,\n",
       "  6,\n",
       "  57,\n",
       "  105,\n",
       "  67,\n",
       "  7,\n",
       "  11,\n",
       "  23671,\n",
       "  274,\n",
       "  23671,\n",
       "  81,\n",
       "  23671,\n",
       "  23671,\n",
       "  20,\n",
       "  23671,\n",
       "  23671,\n",
       "  94,\n",
       "  27,\n",
       "  118,\n",
       "  29,\n",
       "  100,\n",
       "  88,\n",
       "  12,\n",
       "  22,\n",
       "  2,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  13,\n",
       "  23671,\n",
       "  23671,\n",
       "  214,\n",
       "  5,\n",
       "  275,\n",
       "  23671,\n",
       "  85,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  6,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  32,\n",
       "  23671,\n",
       "  42,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  60,\n",
       "  23671,\n",
       "  23671,\n",
       "  214,\n",
       "  85,\n",
       "  23671,\n",
       "  23671,\n",
       "  282,\n",
       "  406,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  2,\n",
       "  23671,\n",
       "  23671,\n",
       "  11,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  2,\n",
       "  23671,\n",
       "  8,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  6,\n",
       "  2,\n",
       "  23671,\n",
       "  42,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  59,\n",
       "  23671,\n",
       "  36,\n",
       "  23671,\n",
       "  23671,\n",
       "  2,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  45,\n",
       "  23671,\n",
       "  2,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  8,\n",
       "  23671,\n",
       "  110,\n",
       "  2,\n",
       "  23671,\n",
       "  23671,\n",
       "  6,\n",
       "  247,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  11,\n",
       "  23671,\n",
       "  23671,\n",
       "  11,\n",
       "  23671,\n",
       "  274,\n",
       "  57,\n",
       "  105,\n",
       "  67,\n",
       "  23671,\n",
       "  6,\n",
       "  57,\n",
       "  105,\n",
       "  67,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671],\n",
       " [23671,\n",
       "  23671,\n",
       "  73,\n",
       "  137,\n",
       "  73,\n",
       "  23671,\n",
       "  17,\n",
       "  14,\n",
       "  23671,\n",
       "  247,\n",
       "  23671,\n",
       "  20,\n",
       "  23671,\n",
       "  219,\n",
       "  23671,\n",
       "  23671,\n",
       "  2,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  71,\n",
       "  23671,\n",
       "  298,\n",
       "  23671,\n",
       "  23671,\n",
       "  42,\n",
       "  8,\n",
       "  23671,\n",
       "  2,\n",
       "  23671,\n",
       "  252,\n",
       "  11,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  11,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  13,\n",
       "  9,\n",
       "  14,\n",
       "  211,\n",
       "  174,\n",
       "  23671,\n",
       "  44,\n",
       "  23671,\n",
       "  23671,\n",
       "  23671,\n",
       "  94,\n",
       "  89,\n",
       "  23671,\n",
       "  86,\n",
       "  23671,\n",
       "  23671,\n",
       "  46,\n",
       "  23671,\n",
       "  58,\n",
       "  52,\n",
       "  3,\n",
       "  31]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# извлечем текст для формирования токенайзера\n",
    "def extract_text(im):\n",
    "    try:\n",
    "        # распознаем документ\n",
    "        if any(i in im.lower() for i in ['jpeg', 'jpg', 'bmp', 'png']):\n",
    "            img = Image.open(im)\n",
    "        elif 'pdf' in im.lower():\n",
    "            img = convert_from_path(im, \n",
    "                                    poppler_path=r'C:\\poppler-0.90.1\\bin', \n",
    "                                    single_file=True)\n",
    "\n",
    "        # извлечем текст\n",
    "        txt = image_to_string(img, config='-l eng+rus --oem 3 --psm 3')\n",
    "        txt = re.sub('[\\W\\s_]{1,}', ' ', txt.lower())\n",
    "    except:\n",
    "        txt = 'unknown'\n",
    "    print('{:*^100}'.format(im+': '+('True' if txt!='unknown' else 'False')))\n",
    "    return txt\n",
    "\n",
    "\n",
    "\n",
    "texts = []\n",
    "for i in tqdm.tqdm(range(file2class.shape[0])):\n",
    "    texts.append(extract_text(os.path.join(path, file2class['category'].iloc[i], file2class['filename'].iloc[i])))\n",
    "\n",
    "file2class['text'] = texts\n",
    "\n",
    "maxlen = 500 \n",
    "\n",
    "# создадим токенизатор\n",
    "tokenizer = Tokenizer(num_words=maxlen, filters='!\"#$%&()*+,-–—./:;<=>?@[\\\\]^_`{|}~\\t\\n\\xa0', lower=True, split=' ', oov_token='unknown', char_level=False)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "items = list(tokenizer.word_index.items())\n",
    "items[:2]\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "sequences[:2]\n",
    "\n",
    "# # преобразуем в one hot encoding формат\n",
    "# xTrainRez01 = tokenizer.sequences_to_matrix(sequences) \n",
    "# print(xTrainRez01.shape)                                      \n",
    "# print(xTrainRez01[0][0:100]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генератор обучающей и тренирововчной выборки для текста и изображения\n",
    "\n",
    "\n",
    "\n",
    "img_width = 120 #Ширина изображения\n",
    "img_height = 360 #Высота изображения\n",
    "classes = 30\n",
    "\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    \"\"\"\n",
    "    Keras Sequence object to train a model on larger-than-memory data.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path, batch_size, im_list, labels, data_type, mode='train'):\n",
    "        self.bsz = batch_size\n",
    "        self.labels = labels\n",
    "        self.im_list = im_list\n",
    "        self.mode = mode\n",
    "        self.data_type = data_type\n",
    "        self.batch_x = 0\n",
    "        self.batch_y = 0\n",
    "        self.batch_x_ros = 0\n",
    "        self.batch_y_ros = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(math.ceil(len(self.labels) / float(self.bsz)))\n",
    "\n",
    "    # загружаем изображение по входящей ссылке на файл\n",
    "    def load_image(self, im):\n",
    "        #         print(im)\n",
    "        # распознаем документ\n",
    "        if any(i in im.lower() for i in ['jpeg', 'jpg', 'bmp', 'png']):\n",
    "            img = Image.open(im)\n",
    "        elif 'pdf' in im.lower():\n",
    "            img = convert_from_path(im, \n",
    "                                    poppler_path=r'C:\\poppler-0.90.1\\bin', \n",
    "                                    single_file=True)[0]\n",
    "        else:\n",
    "            raise Exception(f'unknown file type: {im}')\n",
    "        return img    \n",
    "    \n",
    "    # извлекаем данные с изображения\n",
    "    def extract_image(self, img):\n",
    "\n",
    "        # проверим на цветовую гамму, если не RGB, то конвертируем в RGB\n",
    "        if img.mode!='RGB':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        return img_to_array(img.resize((img_width, img_height), 3)) / 255.\n",
    "    \n",
    "    # извлечем текст\n",
    "    def extract_text(self, im):\n",
    "#         корректый код при чтении из файла\n",
    "        try:\n",
    "            txt = image_to_string(img, config='-l eng+rus --oem 3 --psm 3')\n",
    "            txt = re.sub('[\\W\\s_]{1,}', ' ', txt.lower())\n",
    "        except:\n",
    "            txt = 'unknown'\n",
    "        print('{:*^100}'.format(filename+': '+('True' if txt!='' else 'False')))\n",
    "        \n",
    "        if not txt:\n",
    "            txt = 'unknown'\n",
    "#         print(txt)\n",
    "        return txt\n",
    "\n",
    "    # векторизуем текст в one hot encoding длины maxlen\n",
    "    def vectorize_text(self, txt):\n",
    "        sequence = tokenizer.texts_to_sequences([txt])\n",
    "        vector = np.asarray(tokenizer.sequences_to_matrix(sequence)[0])\n",
    "#         print(vector.shape)\n",
    "        return vector\n",
    "        \n",
    "\n",
    "    def oversampling(self):\n",
    "        cntr = Counter(np.argmax(self.batch_y, axis=1))\n",
    "        max_cnt = max(cntr.values())\n",
    "#         print(max_cnt)\n",
    "\n",
    "        y_list = np.argmax(self.batch_y, axis=1)\n",
    "        y_dict_new = dict(cntr)\n",
    "        x_batch_new = []\n",
    "        y_list_new = []\n",
    "        for i in range(len(y_list)):\n",
    "            if y_dict_new[y_list[i]]<max_cnt:\n",
    "                for _ in range(2):\n",
    "                    x_batch_new.append(self.batch_x[i])\n",
    "                    y_list_new.append(y_list[i])\n",
    "                    y_dict_new[y_list[i]]+=1\n",
    "            else:\n",
    "                x_batch_new.append(self.batch_x[i])\n",
    "                y_list_new.append(y_list[i])\n",
    "                y_dict_new[y_list[i]]+=1\n",
    "        return np.asarray(x_batch_new), to_categorical(np.asarray(y_list_new), num_classes=classes)\n",
    "    \n",
    "    \n",
    "#     перемешиваем все элементы, когда находимся в режиме обучения\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = range(len(self.labels))\n",
    "        if self.mode == 'train':\n",
    "            self.indexes = random.sample(self.indexes, k=len(self.indexes))\n",
    "\n",
    "    # формируем батч из меток класса, который хранится в памяти\n",
    "    def get_batch_labels(self, idx):\n",
    "        return self.labels[idx * self.bsz: (idx + 1) * self.bsz]\n",
    "    \n",
    "    # формируем батч фичей, которые будут извлечены из изображений на диске\n",
    "    def get_batch_features(self, idx):\n",
    "        if self.data_type=='image':\n",
    "            return np.array([self.extract_image(self.load_image(im)) for im in self.im_list[idx * self.bsz: (1 + idx) * self.bsz]])\n",
    "        elif self.data_type=='text':\n",
    "#             раскомментить при извлечении текста с нуля            \n",
    "            return np.array([self.vectorize_text(self.extract_text(self.load_image(im))) for im in self.im_list[idx * self.bsz: (1 + idx) * self.bsz]])\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        self.batch_x = self.get_batch_features(idx)\n",
    "        self.batch_y =self.get_batch_labels(idx)\n",
    "#         print(self.batch_x.shape)\n",
    "#         print(self.batch_y.shape)\n",
    "#         if self.data_type=='image':\n",
    "#             self.batch_x = self.batch_x.reshape((self.bsz, img_width*img_height*3))\n",
    "\n",
    "#  oversampling\n",
    "#         self.batch_x_ros, self.batch_y_ros = ros.fit_resample(self.batch_x, self.batch_y)\n",
    "#         self.batch_y_ros = to_categorical(self.batch_y_ros,30)\n",
    "        self.batch_x_ros, self.batch_y_ros = self.oversampling()\n",
    "#         print(self.batch_x_ros.shape, self.batch_x.shape)\n",
    "#         print(self.batch_y_ros.shape, self.batch_y.shape)\n",
    "\n",
    "        return self.batch_x_ros, self.batch_y_ros\n",
    "#         return self.batch_x, self.batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем обучающую и проверочную выборки\n",
    "validation_split = 0.1\n",
    "batch = 64\n",
    "\n",
    "labels = to_categorical(np.asarray(file2class['target'].tolist()))\n",
    "im_list = file2class[['category', 'filename']].apply(lambda x: os.path.join(path, x[0], x[1]), axis=1).tolist()\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(im_list, \n",
    "                                                    labels, \n",
    "                                                    test_size=validation_split, \n",
    "                                                    random_state=777,\n",
    "                                                    shuffle=True)\n",
    "\n",
    "\n",
    "# image generator\n",
    "train_gen_image = DataGenerator(path, batch, x_train, y_train, 'image')\n",
    "test_gen_image = DataGenerator(path, batch, x_test, y_test, 'image')\n",
    "# text generator\n",
    "train_gen_text = DataGenerator(path, batch, x_train, y_train, 'text')\n",
    "test_gen_text = DataGenerator(path, batch, x_test, y_test, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генератор для подачи одновременно и генератора изображений и генератора текста на вход\n",
    "class MultipleInputGenerator(Sequence):\n",
    "    \"\"\"Wrapper of 2 ImageDataGenerator\"\"\"\n",
    "\n",
    "    def __init__(self, data_path, batch_size, im_list, labels, train_test_type):\n",
    "        \n",
    "        if train_test_type=='train':\n",
    "            self.gen_image = DataGenerator(path, batch, x_train, y_train, 'image')\n",
    "            self.gen_text = DataGenerator(path, batch, x_train, y_train, 'text')\n",
    "        elif train_test_type=='test':\n",
    "            self.gen_image = DataGenerator(path, batch, x_test, y_test, 'image')\n",
    "            self.gen_text = DataGenerator(path, batch, x_test, y_test, 'text')\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"It is mandatory to implement it on Keras Sequence\"\"\"\n",
    "        return self.gen_image.__len__()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Getting items from the 2 generators and packing them\"\"\"\n",
    "        X1_batch, Y_batch = self.gen_image.__getitem__(index)\n",
    "        X2_batch, Y_batch = self.gen_text.__getitem__(index)\n",
    "\n",
    "        X_batch = [X1_batch, X2_batch]\n",
    "\n",
    "        return X_batch, Y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "int_image (InputLayer)          [(None, 120, 360, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 120, 360, 3)  12          int_image[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "img_conv2d_1 (Conv2D)           (None, 120, 360, 32) 896         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "img_conv2d_2 (Conv2D)           (None, 120, 360, 64) 18496       img_conv2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 120, 360, 64) 0           img_conv2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 40, 120, 64)  0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "img_conv2d_3 (Conv2D)           (None, 40, 120, 128) 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 13, 40, 128)  0           img_conv2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flaten_img (Flatten)            (None, 66560)        0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "img_dense_1 (Dense)             (None, 6144)         408950784   flaten_img[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6144)         0           img_dense_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "int_text (InputLayer)           [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "img_dense_2 (Dense)             (None, 2048)         12584960    dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "text_dense_1 (Dense)            (None, 500)          250500      int_text[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "img_dense_3 (Dense)             (None, 1024)         2098176     img_dense_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "text_dense_2 (Dense)            (None, 200)          100200      text_dense_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           img_dense_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 200)          0           text_dense_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "img_dense_4 (Dense)             (None, 128)          131200      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "text_dense_3 (Dense)            (None, 128)          25728       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 128)          0           img_dense_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 128)          0           text_dense_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concat (Concatenate)            (None, 256)          0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flaten_concat (Flatten)         (None, 256)          0           concat[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_dense_1 (Dense)          (None, 200)          51400       flaten_concat[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 200)          0           concat_dense_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concat_dense_2 (Dense)          (None, 100)          20100       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 100)          0           concat_dense_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concat_dense_3 (Dense)          (None, 50)           5050        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 30)           1530        concat_dense_3[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 424,312,888\n",
      "Trainable params: 424,312,882\n",
      "Non-trainable params: 6\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# модель\n",
    "inp_img = Input(shape=(img_width, img_height, 3), name='int_image')\n",
    "x = BatchNormalization()(inp_img)\n",
    "x = Conv2D(32, (3,3), padding='same', activation='relu', name='img_conv2d_1')(x)\n",
    "x = Conv2D(64, (3,3), padding='same', activation='relu', name='img_conv2d_2')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = MaxPooling2D(pool_size=(3,3))(x)\n",
    "x = Conv2D(128, (3,3), padding='same', activation='relu', name='img_conv2d_3')(x)\n",
    "x = MaxPooling2D(pool_size=(3,3))(x)\n",
    "x = Flatten(name='flaten_img')(x)\n",
    "# inp_img = Input(shape=(img_width*img_height*3,), name='int_image')\n",
    "x = Dense(6144, activation='relu', name='img_dense_1')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(2048, activation='relu', name='img_dense_2')(x)\n",
    "x = Dense(1024, activation='relu', name='img_dense_3')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu', name='img_dense_4')(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "inp_text = Input(shape=(maxlen), name='int_text')\n",
    "# x2 = BatchNormalization()(inp_text)\n",
    "x2 = Dense(500, activation='relu', name='text_dense_1')(inp_text)\n",
    "x2 = Dense(200, activation='relu', name='text_dense_2')(x2)\n",
    "x2 = Dropout(0.3)(x2)\n",
    "x2 = Dense(128, activation='relu', name='text_dense_3')(x2)\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "x_out = Concatenate(name='concat')([x,x2])\n",
    "x_out = Flatten(name='flaten_concat')(x_out)\n",
    "x_out = Dense(200, activation='relu', name='concat_dense_1')(x_out)\n",
    "x_out = Dropout(0.3)(x_out)\n",
    "x_out = Dense(100, activation='relu', name='concat_dense_2')(x_out)\n",
    "x_out = Dropout(0.3)(x_out)\n",
    "x_out = Dense(50, activation='relu', name='concat_dense_3')(x_out)\n",
    "\n",
    "output = Dense(classes, activation='softmax', name='output')(x_out)\n",
    "model = Model([inp_img, inp_text], output)\n",
    "\n",
    "#Компилируем сеть\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=Adam(lr=1e-3), \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <timed eval>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/15\n",
      "48/48 [==============================] - 570s 12s/step - loss: 3.4080 - accuracy: 0.1276 - val_loss: 2.6396 - val_accuracy: 0.3914\n",
      "Epoch 2/15\n",
      "48/48 [==============================] - 510s 11s/step - loss: 2.0674 - accuracy: 0.3882 - val_loss: 1.6183 - val_accuracy: 0.5479\n",
      "Epoch 3/15\n",
      "48/48 [==============================] - 498s 10s/step - loss: 1.4161 - accuracy: 0.5909 - val_loss: 1.2766 - val_accuracy: 0.6712\n",
      "Epoch 4/15\n",
      "48/48 [==============================] - 490s 10s/step - loss: 1.0401 - accuracy: 0.7073 - val_loss: 1.1664 - val_accuracy: 0.6888\n",
      "Epoch 5/15\n",
      "48/48 [==============================] - 524s 11s/step - loss: 0.8370 - accuracy: 0.7628 - val_loss: 1.0756 - val_accuracy: 0.7104\n",
      "Epoch 6/15\n",
      "48/48 [==============================] - 507s 11s/step - loss: 0.6802 - accuracy: 0.8098 - val_loss: 1.0454 - val_accuracy: 0.7436\n",
      "Epoch 7/15\n",
      "48/48 [==============================] - 525s 11s/step - loss: 0.5196 - accuracy: 0.8475 - val_loss: 1.1382 - val_accuracy: 0.7593\n",
      "Epoch 8/15\n",
      "48/48 [==============================] - 484s 10s/step - loss: 0.4537 - accuracy: 0.8700 - val_loss: 1.2567 - val_accuracy: 0.7534\n",
      "Epoch 9/15\n",
      "48/48 [==============================] - 475s 10s/step - loss: 0.3806 - accuracy: 0.8922 - val_loss: 1.1263 - val_accuracy: 0.7671\n",
      "Epoch 10/15\n",
      "48/48 [==============================] - 544s 11s/step - loss: 0.2893 - accuracy: 0.9190 - val_loss: 1.2944 - val_accuracy: 0.7652\n",
      "Epoch 11/15\n",
      "48/48 [==============================] - 484s 10s/step - loss: 0.2504 - accuracy: 0.9301 - val_loss: 1.4462 - val_accuracy: 0.7613\n",
      "Epoch 12/15\n",
      "48/48 [==============================] - 501s 10s/step - loss: 0.2087 - accuracy: 0.9399 - val_loss: 1.4018 - val_accuracy: 0.7730\n",
      "Epoch 13/15\n",
      "48/48 [==============================] - 484s 10s/step - loss: 0.2109 - accuracy: 0.9416 - val_loss: 1.3820 - val_accuracy: 0.7926\n",
      "Epoch 14/15\n",
      "48/48 [==============================] - 486s 10s/step - loss: 0.1892 - accuracy: 0.9497 - val_loss: 1.4942 - val_accuracy: 0.7886\n",
      "Epoch 15/15\n",
      "48/48 [==============================] - 479s 10s/step - loss: 0.1617 - accuracy: 0.9582 - val_loss: 1.6098 - val_accuracy: 0.7867\n",
      "Wall time: 2h 9min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b781f683c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(MultipleInputGenerator(path, batch, x_train, y_train, 'train'), \n",
    "                    epochs=15, \n",
    "                    validation_data = MultipleInputGenerator(path, batch, x_test, y_test, 'test'),\n",
    "                    verbose=1, \n",
    "                    use_multiprocessing=False, \n",
    "                    workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (128, 30)\n",
    "# (128, 500)\n",
    "# (128, 30)\n",
    "# (128, 360, 120, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Оображаем график точности обучения\n",
    "plt.plot(model.history.history['accuracy'], \n",
    "         label='Доля верных ответов на обучающем наборе')\n",
    "plt.plot(model.history.history['val_accuracy'], \n",
    "         label='Доля верных ответов на проверочном наборе')\n",
    "plt.xlabel('Эпоха обучения')\n",
    "plt.ylabel('Доля верных ответов')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# сохраним модель в json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(r'F:\\documents\\result\\docs_classification_model.json', \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(r'F:\\documents\\result\\json_model_weights.hdf5')\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# load json and create model\n",
    "json_file = open(r'F:\\documents\\result\\docs_classification_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(r'F:\\documents\\result\\json_model_weights.hdf5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss=\"categorical_crossentropy\", \n",
    "                      optimizer=Adam(lr=1e-3), \n",
    "                      metrics=[\"accuracy\"])\n",
    "score = loaded_model.evaluate([get_batch_features(x_test, 'image'), get_batch_features(x_test, 'text')], y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "\n",
    "# accuracy: 78.87%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем изображение по входящей ссылке на файл\n",
    "def load_image(im):\n",
    "    #         print(im)\n",
    "    # распознаем документ\n",
    "    if any(i in im.lower() for i in ['jpeg', 'jpg', 'bmp', 'png']):\n",
    "        img = Image.open(im)\n",
    "    elif 'pdf' in im.lower():\n",
    "        img = convert_from_path(im, \n",
    "                                poppler_path=r'C:\\poppler-0.90.1\\bin', \n",
    "                                single_file=True)[0]\n",
    "    else:\n",
    "        raise Exception(f'unknown file type: {im}')\n",
    "    return img    \n",
    "\n",
    "# извлекаем данные с изображения\n",
    "def extract_image(img):\n",
    "\n",
    "    # проверим на цветовую гамму, если не RGB, то конвертируем в RGB\n",
    "    if img.mode!='RGB':\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "    return img_to_array(img.resize((img_width, img_height), 3)) / 255.\n",
    "\n",
    "# извлечем текст\n",
    "def extract_text(img, filename):\n",
    "#     корректый код при чтении из файла\n",
    "    try:\n",
    "        txt = image_to_string(img, config='-l eng+rus --oem 3 --psm 3')\n",
    "        txt = re.sub('[\\W\\s_]{1,}', ' ', txt.lower())\n",
    "    except:\n",
    "        txt = 'unknown'\n",
    "    print('{:*^100}'.format(filename +': '+('True' if txt!='' else 'False')))\n",
    "\n",
    "    if len(txt)==0:\n",
    "        txt = 'unknown'\n",
    "#         print(txt)\n",
    "    return txt\n",
    "\n",
    "# векторизуем текст в one hot encoding длины maxlen\n",
    "def vectorize_text(txt):\n",
    "    sequence = tokenizer.texts_to_sequences([txt])\n",
    "    vector = np.asarray(tokenizer.sequences_to_matrix(sequence)[0])\n",
    "#         print(vector.shape)\n",
    "    return vector\n",
    "\n",
    "\n",
    "def get_batch_features(im_list, data_type):\n",
    "    if data_type=='image':\n",
    "        return np.array([extract_image(load_image(im)) for im in im_list])\n",
    "    elif data_type=='text':\n",
    "    #             раскомментить при извлечении текста с нуля            \n",
    "        return np.array([vectorize_text(extract_text(load_image(im), im)) for im in im_list])\n",
    "    #         return np.array([vectorize_text(extract_text(im)) for im in im_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([get_batch_features(x_test, 'image'), get_batch_features(x_test, 'text')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.79      0.92      0.85        12\n",
      "           3       1.00      0.50      0.67         6\n",
      "           4       1.00      0.33      0.50         3\n",
      "           5       0.67      1.00      0.80         2\n",
      "           6       1.00      0.50      0.67         4\n",
      "           7       1.00      1.00      1.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       1.00      0.83      0.91         6\n",
      "          13       0.83      0.81      0.82        31\n",
      "          14       0.84      0.90      0.87        29\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       0.86      0.73      0.79        26\n",
      "          17       0.83      1.00      0.91         5\n",
      "          18       1.00      0.50      0.67         2\n",
      "          19       1.00      0.80      0.89         5\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.77      0.81      0.79        62\n",
      "          22       0.92      1.00      0.96        23\n",
      "          23       0.51      0.62      0.56        37\n",
      "          25       1.00      0.75      0.86        12\n",
      "          26       0.90      0.78      0.84        46\n",
      "          27       0.75      1.00      0.86         3\n",
      "          28       0.88      0.88      0.88        16\n",
      "\n",
      "    accuracy                           0.79       336\n",
      "   macro avg       0.77      0.69      0.71       336\n",
      "weighted avg       0.82      0.79      0.79       336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# after oversampling\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           2       0.62      0.83      0.71        12\n",
      "           3       0.60      0.50      0.55         6\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.40      1.00      0.57         2\n",
      "           6       0.57      1.00      0.73         4\n",
      "           7       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.67      0.67      0.67         6\n",
      "          13       1.00      0.87      0.93        31\n",
      "          14       0.96      0.90      0.93        29\n",
      "          15       1.00      1.00      1.00         2\n",
      "          16       0.68      0.73      0.70        26\n",
      "          17       0.71      1.00      0.83         5\n",
      "          18       0.50      0.50      0.50         2\n",
      "          19       0.75      0.60      0.67         5\n",
      "          20       0.00      0.00      0.00         1\n",
      "          21       0.90      0.74      0.81        62\n",
      "          22       0.92      0.96      0.94        23\n",
      "          23       0.46      0.70      0.55        37\n",
      "          25       0.91      0.83      0.87        12\n",
      "          26       0.84      0.80      0.82        46\n",
      "          27       1.00      0.67      0.80         3\n",
      "          28       1.00      0.69      0.81        16\n",
      "\n",
      "    accuracy                           0.77       336\n",
      "   macro avg       0.60      0.62      0.60       336\n",
      "weighted avg       0.80      0.77      0.78       336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# before oversampling\n",
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(predictions, axis=1)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env3",
   "language": "python",
   "name": "test-env3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
